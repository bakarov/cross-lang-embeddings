{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T10:53:08.094905Z",
     "start_time": "2018-02-22T10:53:08.031601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "import os, datetime\n",
    "from gensim.models import KeyedVectors\n",
    "from pandas import read_csv\n",
    "import pandas\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import PolynomialFeatures, FunctionTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import skorch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "alpha_tokenizer = RegexpTokenizer('[А-Яа-яA-Za-z]\\w+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrinsic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:14:55.487221Z",
     "start_time": "2018-02-21T14:14:55.206813Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_essays = read_csv('../../plag/essays/good_essays_FORMATTED.csv')[['original_sentence', 'modified_sentence']].dropna().reset_index(drop=True)\n",
    "all_essays = read_csv('../../plag/essays/all_essays_FORMATTED.csv')[['original_sentence', 'modified_sentence']].dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:14:55.577887Z",
     "start_time": "2018-02-21T14:14:55.489806Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paraphrases = read_csv('../../plag/cross-lang-paraphrase-with-docs.csv').sample(frac=1).reset_index(drop=True)\n",
    "strict_train_test_data = [(paraphrases.iloc[train_idx], paraphrases.iloc[test_idx]) for train_idx, test_idx in\n",
    "                          GroupKFold(n_splits=3).split(paraphrases, paraphrases.is_paraphrase.values, paraphrases.document.values)]\n",
    "mixed_train_test_data = [(paraphrases.iloc[train_idx], paraphrases.iloc[test_idx]) for train_idx, test_idx in\n",
    "                         KFold(n_splits=3, shuffle=True).split(paraphrases, paraphrases.is_paraphrase.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T06:48:38.877836Z",
     "start_time": "2018-02-22T06:48:21.841492Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/numpy/lib/arraysetops.py:463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "yandex = read_csv('../../corpora/parallel/yandex/yandex_with_negative_sim.csv', index_col=0).sample(frac=1).reset_index(drop=True)\n",
    "yandex_train_test_data = [(yandex.iloc[train_idx], yandex.iloc[test_idx]) for train_idx, test_idx in\n",
    "                          KFold(n_splits=3).split(yandex, yandex.is_paraphrase.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T06:48:39.197508Z",
     "start_time": "2018-02-22T06:48:38.879310Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXTRINSIC_DATASETS = (\n",
    "    ('para strict', strict_train_test_data),\n",
    "#     ('para mixed', mixed_train_test_data),\n",
    "    ('yandex wmt', yandex_train_test_data),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:15:11.843609Z",
     "start_time": "2018-02-21T14:15:11.624687Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_ru_dict = {}\n",
    "\n",
    "with open('../../word-benchmarks/intrinsic/dictionary/en-ru.txt', 'r') as f:\n",
    "    for word_pair in f.read().split('\\n')[:-1]:\n",
    "        en_ru_dict[word_pair.split(' ')[0]] = word_pair.split(' ')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intrinsic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:15:11.862179Z",
     "start_time": "2018-02-21T14:15:11.851152Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english_russian_word_similarity = [\n",
    "                ('../../word-benchmarks/intrinsic/word-similarity/cross-lingual/en-ru/simverb-3500.csv', 'SimVerb-3074'),\n",
    "                ('../../word-benchmarks/men.csv', 'MEN-1146'),\n",
    "                ('../../word-benchmarks/intrinsic/word-similarity/cross-lingual/en-ru/rw.csv', 'RareWord-968'),\n",
    "                ('../../word-benchmarks/intrinsic/word-similarity/cross-lingual/en-ru/simlex999.csv', 'SimLex-739'),\n",
    "                ('../../word-benchmarks/intrinsic/word-similarity/cross-lingual/en-ru/mturk-771.csv', 'MTurk-551'),\n",
    "                ('../../word-benchmarks/intrinsic/word-similarity/cross-lingual/en-ru/semeval-2017.csv', 'SemEval-243'),\n",
    "                ('../../word-benchmarks/intrinsic/word-similarity/cross-lingual/en-ru/wordsim353-rel.csv', 'WordRel-193'),\n",
    "                ('../../word-benchmarks/intrinsic/word-similarity/cross-lingual/en-ru/wordsim353-sim.csv', 'WordSim-193'),\n",
    "                ('../../word-benchmarks/intrinsic/word-similarity/cross-lingual/en-ru/verb-143.csv', 'Verb-115'),\n",
    "                ('../../word-benchmarks/intrinsic/word-similarity/cross-lingual/en-ru/yp-130.csv', 'YP-111'),\n",
    "                ('../../word-benchmarks/rg-65.csv', 'RG-54'),\n",
    "                ('../../word-benchmarks/mc-30.csv', 'MC-28'),\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:15:12.163940Z",
     "start_time": "2018-02-21T14:15:11.869317Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_keyed_vectors_if_not_exists(src_path, target_path):\n",
    "    if os.path.exists(target_path):\n",
    "        return\n",
    "    model = KeyedVectors.load_word2vec_format(src_path)\n",
    "    model.save(target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vecmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:15:29.519463Z",
     "start_time": "2018-02-21T14:15:12.165782Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convert_keyed_vectors_if_not_exists('../cross-lang/MODELS/vecmap/en.vec', '../cross-lang/MODELS/vecmap/en.gensim')\n",
    "convert_keyed_vectors_if_not_exists('../cross-lang/MODELS/vecmap/ru.vec', '../cross-lang/MODELS/vecmap/ru.gensim')\n",
    "vecmap_en = KeyedVectors.load('../cross-lang/MODELS/vecmap/en.gensim', mmap='r')\n",
    "vecmap_ru = KeyedVectors.load('../cross-lang/MODELS/vecmap/ru.gensim', mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MUSE supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:15:30.700263Z",
     "start_time": "2018-02-21T14:15:29.521648Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convert_keyed_vectors_if_not_exists('../cross-lang/MODELS/muse_supervised/2db0qcgzth/vectors-en.txt', '../cross-lang/MODELS/muse_supervised/2db0qcgzth/vectors-en.gensim')\n",
    "convert_keyed_vectors_if_not_exists('../cross-lang/MODELS/muse_supervised/2db0qcgzth/vectors-ru.txt', '../cross-lang/MODELS/muse_supervised/2db0qcgzth/vectors-ru.gensim')\n",
    "muse_s_en = KeyedVectors.load('../cross-lang/MODELS/muse_supervised/2db0qcgzth/vectors-en.gensim', mmap='r')\n",
    "muse_s_ru = KeyedVectors.load('../cross-lang/MODELS/muse_supervised/2db0qcgzth/vectors-ru.gensim', mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MUSE unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:15:31.866136Z",
     "start_time": "2018-02-21T14:15:30.702137Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convert_keyed_vectors_if_not_exists('../cross-lang/MODELS/muse_unsupervised/vectors-en.txt', '../cross-lang/MODELS/muse_unsupervised/vectors-en.gensim')\n",
    "convert_keyed_vectors_if_not_exists('../cross-lang/MODELS/muse_unsupervised/vectors-ru.txt', '../cross-lang/MODELS/muse_unsupervised/vectors-ru.gensim')\n",
    "muse_u_en = KeyedVectors.load('../cross-lang/MODELS/muse_unsupervised/vectors-en.gensim', mmap='r')\n",
    "muse_u_ru = KeyedVectors.load('../cross-lang/MODELS/muse_unsupervised/vectors-ru.gensim', mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bilingual CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:15:48.946239Z",
     "start_time": "2018-02-21T14:15:31.868304Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convert_keyed_vectors_if_not_exists('../cross-lang/MODELS/BiCCA/wiki.en.vec.ccaed.vec', '../cross-lang/MODELS/BiCCA/wiki.en.vec.ccaed.gensim')\n",
    "convert_keyed_vectors_if_not_exists('../cross-lang/MODELS/BiCCA/wiki.ru.vec.ccaed.vec', '../cross-lang/MODELS/BiCCA/wiki.ru.vec.ccaed.gensim')\n",
    "bi_cca_en = KeyedVectors.load('../cross-lang/MODELS/BiCCA/wiki.en.vec.ccaed.gensim', mmap='r')\n",
    "bi_cca_ru = KeyedVectors.load('../cross-lang/MODELS/BiCCA/wiki.ru.vec.ccaed.gensim', mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultiFastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:16:07.412403Z",
     "start_time": "2018-02-21T14:15:48.953521Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convert_keyed_vectors_if_not_exists('../cross-lang/MODELS/MFT/mft-en.vec', '../cross-lang/MODELS/MFT/mft-en.gensim')\n",
    "convert_keyed_vectors_if_not_exists('../cross-lang/MODELS/MFT/mft-ru.vec', '../cross-lang/MODELS/MFT/mft-ru.gensim')\n",
    "mft_en = KeyedVectors.load('../cross-lang/MODELS/MFT/mft-en.gensim', mmap='r')\n",
    "mft_ru = KeyedVectors.load('../cross-lang/MODELS/MFT/mft-ru.gensim', mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:16:07.418026Z",
     "start_time": "2018-02-21T14:16:07.415585Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mft_en.vector_size = mft_en.n_dim\n",
    "# mft_ru.vector_size = mft_ru.n_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:16:07.513515Z",
     "start_time": "2018-02-21T14:16:07.419905Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [(vecmap_en, vecmap_ru, 'Vecmap'),\n",
    "         (muse_s_en, muse_s_ru, 'MSE'),\n",
    "         (muse_u_en, muse_u_ru, 'MUE'),\n",
    "         (bi_cca_en, bi_cca_ru, 'BiCCA'),\n",
    "         (mft_en, mft_ru, 'MFT')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate intrinsic scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:16:07.610518Z",
     "start_time": "2018-02-21T14:16:07.515282Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_vector(word, model, vector_size=300):\n",
    "    if len(word.split(' ')) == 1:\n",
    "        return model[word]\n",
    "    else:\n",
    "        vector = np.zeros(shape=model.vector_size)\n",
    "        for subword in word.split(' '):\n",
    "            vector = np.add(vector, model[subword])\n",
    "        return vector / len(word.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:16:07.710408Z",
     "start_time": "2018-02-21T14:16:07.612384Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_cosines(dataset, src_embeddings, trg_embeddings, verbose=True):\n",
    "    dataset_len = len(dataset)\n",
    "    vector_sims = []\n",
    "    human_sims = []\n",
    "    for i, m in dataset.iterrows():\n",
    "        try:\n",
    "            vector_sims.append(1 - cosine(get_word_vector(m['word1'].lower(), src_embeddings),\n",
    "                                          get_word_vector(m['word2'].lower(), trg_embeddings)))\n",
    "            human_sims.append(m['similarity'])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if verbose:\n",
    "        print('Percent of dropped = {:2.1f}%, amount of remanining words = {}'.format((dataset_len - len(human_sims))/dataset_len*100, len(human_sims)))\n",
    "    return np.array(vector_sims), np.array(human_sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:16:11.616665Z",
     "start_time": "2018-02-21T14:16:07.712228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of dropped = 1.3%, amount of remanining words = 3455\n",
      "SimVerb-3074: Correlation with Russian human judgements of English word2vec vectors: 0.23 (0.00)\n",
      "Percent of dropped = 0.3%, amount of remanining words = 2990\n",
      "MEN-1146: Correlation with Russian human judgements of English word2vec vectors: 0.69 (0.00)\n",
      "Percent of dropped = 5.1%, amount of remanining words = 1931\n",
      "RareWord-968: Correlation with Russian human judgements of English word2vec vectors: 0.43 (0.00)\n",
      "Percent of dropped = 0.5%, amount of remanining words = 994\n",
      "SimLex-739: Correlation with Russian human judgements of English word2vec vectors: 0.35 (0.00)\n",
      "Percent of dropped = 0.6%, amount of remanining words = 766\n",
      "MTurk-551: Correlation with Russian human judgements of English word2vec vectors: 0.57 (0.00)\n",
      "Percent of dropped = 3.8%, amount of remanining words = 481\n",
      "SemEval-243: Correlation with Russian human judgements of English word2vec vectors: 0.61 (0.00)\n",
      "Percent of dropped = 0.4%, amount of remanining words = 251\n",
      "WordRel-193: Correlation with Russian human judgements of English word2vec vectors: 0.57 (0.00)\n",
      "Percent of dropped = 1.0%, amount of remanining words = 201\n",
      "WordSim-193: Correlation with Russian human judgements of English word2vec vectors: 0.72 (0.00)\n",
      "Percent of dropped = 3.1%, amount of remanining words = 126\n",
      "Verb-115: Correlation with Russian human judgements of English word2vec vectors: 0.27 (0.00)\n",
      "Percent of dropped = 0.0%, amount of remanining words = 130\n",
      "YP-111: Correlation with Russian human judgements of English word2vec vectors: 0.25 (0.00)\n",
      "Percent of dropped = 3.1%, amount of remanining words = 63\n",
      "RG-54: Correlation with Russian human judgements of English word2vec vectors: 0.63 (0.00)\n",
      "Percent of dropped = 0.0%, amount of remanining words = 30\n",
      "MC-28: Correlation with Russian human judgements of English word2vec vectors: 0.71 (0.00)\n"
     ]
    }
   ],
   "source": [
    "for dataset, name in english_russian_word_similarity:\n",
    "    print('{}: Correlation with Russian human judgements of English word2vec vectors: {:0.2f} ({:0.2f})'.format(name ,*spearmanr(*calculate_cosines(read_csv(dataset), vecmap_en, vecmap_ru))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:16:15.181138Z",
     "start_time": "2018-02-21T14:16:11.618745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of dropped = 12.2%, amount of remanining words = 3074\n",
      "SimVerb-3074: Correlation with Russian human judgements of English word2vec vectors: 0.20 (0.00)\n",
      "Percent of dropped = 4.3%, amount of remanining words = 2871\n",
      "MEN-1146: Correlation with Russian human judgements of English word2vec vectors: 0.68 (0.00)\n",
      "Percent of dropped = 43.7%, amount of remanining words = 1146\n",
      "RareWord-968: Correlation with Russian human judgements of English word2vec vectors: 0.44 (0.00)\n",
      "Percent of dropped = 4.1%, amount of remanining words = 958\n",
      "SimLex-739: Correlation with Russian human judgements of English word2vec vectors: 0.34 (0.00)\n",
      "Percent of dropped = 4.2%, amount of remanining words = 739\n",
      "MTurk-551: Correlation with Russian human judgements of English word2vec vectors: 0.56 (0.00)\n",
      "Percent of dropped = 12.0%, amount of remanining words = 440\n",
      "SemEval-243: Correlation with Russian human judgements of English word2vec vectors: 0.60 (0.00)\n",
      "Percent of dropped = 3.6%, amount of remanining words = 243\n",
      "WordRel-193: Correlation with Russian human judgements of English word2vec vectors: 0.55 (0.00)\n",
      "Percent of dropped = 4.9%, amount of remanining words = 193\n",
      "WordSim-193: Correlation with Russian human judgements of English word2vec vectors: 0.69 (0.00)\n",
      "Percent of dropped = 14.6%, amount of remanining words = 111\n",
      "Verb-115: Correlation with Russian human judgements of English word2vec vectors: 0.24 (0.01)\n",
      "Percent of dropped = 11.5%, amount of remanining words = 115\n",
      "YP-111: Correlation with Russian human judgements of English word2vec vectors: 0.22 (0.02)\n",
      "Percent of dropped = 16.9%, amount of remanining words = 54\n",
      "RG-54: Correlation with Russian human judgements of English word2vec vectors: 0.68 (0.00)\n",
      "Percent of dropped = 6.7%, amount of remanining words = 28\n",
      "MC-28: Correlation with Russian human judgements of English word2vec vectors: 0.67 (0.00)\n"
     ]
    }
   ],
   "source": [
    "for dataset, name in english_russian_word_similarity:\n",
    "    print('{}: Correlation with Russian human judgements of English word2vec vectors: {:0.2f} ({:0.2f})'.format(name ,*spearmanr(*calculate_cosines(read_csv(dataset), muse_s_en, muse_s_ru))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:16:18.764841Z",
     "start_time": "2018-02-21T14:16:15.183162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of dropped = 12.2%, amount of remanining words = 3074\n",
      "SimVerb-3074: Correlation with Russian human judgements of English word2vec vectors: 0.20 (0.00)\n",
      "Percent of dropped = 4.3%, amount of remanining words = 2871\n",
      "MEN-1146: Correlation with Russian human judgements of English word2vec vectors: 0.66 (0.00)\n",
      "Percent of dropped = 43.7%, amount of remanining words = 1146\n",
      "RareWord-968: Correlation with Russian human judgements of English word2vec vectors: 0.42 (0.00)\n",
      "Percent of dropped = 4.1%, amount of remanining words = 958\n",
      "SimLex-739: Correlation with Russian human judgements of English word2vec vectors: 0.32 (0.00)\n",
      "Percent of dropped = 4.2%, amount of remanining words = 739\n",
      "MTurk-551: Correlation with Russian human judgements of English word2vec vectors: 0.51 (0.00)\n",
      "Percent of dropped = 12.0%, amount of remanining words = 440\n",
      "SemEval-243: Correlation with Russian human judgements of English word2vec vectors: 0.56 (0.00)\n",
      "Percent of dropped = 3.6%, amount of remanining words = 243\n",
      "WordRel-193: Correlation with Russian human judgements of English word2vec vectors: 0.53 (0.00)\n",
      "Percent of dropped = 4.9%, amount of remanining words = 193\n",
      "WordSim-193: Correlation with Russian human judgements of English word2vec vectors: 0.67 (0.00)\n",
      "Percent of dropped = 14.6%, amount of remanining words = 111\n",
      "Verb-115: Correlation with Russian human judgements of English word2vec vectors: 0.39 (0.00)\n",
      "Percent of dropped = 11.5%, amount of remanining words = 115\n",
      "YP-111: Correlation with Russian human judgements of English word2vec vectors: 0.37 (0.00)\n",
      "Percent of dropped = 16.9%, amount of remanining words = 54\n",
      "RG-54: Correlation with Russian human judgements of English word2vec vectors: 0.67 (0.00)\n",
      "Percent of dropped = 6.7%, amount of remanining words = 28\n",
      "MC-28: Correlation with Russian human judgements of English word2vec vectors: 0.70 (0.00)\n"
     ]
    }
   ],
   "source": [
    "for dataset, name in english_russian_word_similarity:\n",
    "    print('{}: Correlation with Russian human judgements of English word2vec vectors: {:0.2f} ({:0.2f})'.format(name ,*spearmanr(*calculate_cosines(read_csv(dataset), muse_u_en, muse_u_ru))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:16:22.313248Z",
     "start_time": "2018-02-21T14:16:18.766909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of dropped = 1.3%, amount of remanining words = 3455\n",
      "SimVerb-3074: Correlation with Russian human judgements of English word2vec vectors: 0.22 (0.00)\n",
      "Percent of dropped = 0.3%, amount of remanining words = 2990\n",
      "MEN-1146: Correlation with Russian human judgements of English word2vec vectors: 0.66 (0.00)\n",
      "Percent of dropped = 5.1%, amount of remanining words = 1931\n",
      "RareWord-968: Correlation with Russian human judgements of English word2vec vectors: 0.43 (0.00)\n",
      "Percent of dropped = 0.5%, amount of remanining words = 994\n",
      "SimLex-739: Correlation with Russian human judgements of English word2vec vectors: 0.34 (0.00)\n",
      "Percent of dropped = 0.6%, amount of remanining words = 766\n",
      "MTurk-551: Correlation with Russian human judgements of English word2vec vectors: 0.54 (0.00)\n",
      "Percent of dropped = 3.8%, amount of remanining words = 481\n",
      "SemEval-243: Correlation with Russian human judgements of English word2vec vectors: 0.61 (0.00)\n",
      "Percent of dropped = 0.4%, amount of remanining words = 251\n",
      "WordRel-193: Correlation with Russian human judgements of English word2vec vectors: 0.53 (0.00)\n",
      "Percent of dropped = 1.0%, amount of remanining words = 201\n",
      "WordSim-193: Correlation with Russian human judgements of English word2vec vectors: 0.67 (0.00)\n",
      "Percent of dropped = 3.1%, amount of remanining words = 126\n",
      "Verb-115: Correlation with Russian human judgements of English word2vec vectors: 0.27 (0.00)\n",
      "Percent of dropped = 0.0%, amount of remanining words = 130\n",
      "YP-111: Correlation with Russian human judgements of English word2vec vectors: 0.25 (0.00)\n",
      "Percent of dropped = 3.1%, amount of remanining words = 63\n",
      "RG-54: Correlation with Russian human judgements of English word2vec vectors: 0.61 (0.00)\n",
      "Percent of dropped = 0.0%, amount of remanining words = 30\n",
      "MC-28: Correlation with Russian human judgements of English word2vec vectors: 0.72 (0.00)\n"
     ]
    }
   ],
   "source": [
    "for dataset, name in english_russian_word_similarity:\n",
    "    print('{}: Correlation with Russian human judgements of English word2vec vectors: {:0.2f} ({:0.2f})'.format(name ,*spearmanr(*calculate_cosines(read_csv(dataset), bi_cca_en, bi_cca_ru))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:16:26.103543Z",
     "start_time": "2018-02-21T14:16:22.315623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of dropped = 1.3%, amount of remanining words = 3455\n",
      "SimVerb-3074: Correlation with Russian human judgements of English word2vec vectors: 0.21 (0.00)\n",
      "Percent of dropped = 0.3%, amount of remanining words = 2990\n",
      "MEN-1146: Correlation with Russian human judgements of English word2vec vectors: 0.68 (0.00)\n",
      "Percent of dropped = 5.1%, amount of remanining words = 1931\n",
      "RareWord-968: Correlation with Russian human judgements of English word2vec vectors: 0.43 (0.00)\n",
      "Percent of dropped = 0.5%, amount of remanining words = 994\n",
      "SimLex-739: Correlation with Russian human judgements of English word2vec vectors: 0.34 (0.00)\n",
      "Percent of dropped = 0.6%, amount of remanining words = 766\n",
      "MTurk-551: Correlation with Russian human judgements of English word2vec vectors: 0.57 (0.00)\n",
      "Percent of dropped = 3.8%, amount of remanining words = 481\n",
      "SemEval-243: Correlation with Russian human judgements of English word2vec vectors: 0.62 (0.00)\n",
      "Percent of dropped = 0.4%, amount of remanining words = 251\n",
      "WordRel-193: Correlation with Russian human judgements of English word2vec vectors: 0.55 (0.00)\n",
      "Percent of dropped = 1.0%, amount of remanining words = 201\n",
      "WordSim-193: Correlation with Russian human judgements of English word2vec vectors: 0.71 (0.00)\n",
      "Percent of dropped = 3.1%, amount of remanining words = 126\n",
      "Verb-115: Correlation with Russian human judgements of English word2vec vectors: 0.27 (0.00)\n",
      "Percent of dropped = 0.0%, amount of remanining words = 130\n",
      "YP-111: Correlation with Russian human judgements of English word2vec vectors: 0.25 (0.00)\n",
      "Percent of dropped = 3.1%, amount of remanining words = 63\n",
      "RG-54: Correlation with Russian human judgements of English word2vec vectors: 0.67 (0.00)\n",
      "Percent of dropped = 0.0%, amount of remanining words = 30\n",
      "MC-28: Correlation with Russian human judgements of English word2vec vectors: 0.70 (0.00)\n"
     ]
    }
   ],
   "source": [
    "for dataset, name in english_russian_word_similarity:\n",
    "    print('{}: Correlation with Russian human judgements of English word2vec vectors: {:0.2f} ({:0.2f})'.format(name ,*spearmanr(*calculate_cosines(read_csv(dataset), mft_en, mft_ru))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joint table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:16:44.456670Z",
     "start_time": "2018-02-21T14:16:26.105601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SimVerb-3074</th>\n",
       "      <th>MEN-1146</th>\n",
       "      <th>RareWord-968</th>\n",
       "      <th>SimLex-739</th>\n",
       "      <th>MTurk-551</th>\n",
       "      <th>SemEval-243</th>\n",
       "      <th>WordRel-193</th>\n",
       "      <th>WordSim-193</th>\n",
       "      <th>Verb-115</th>\n",
       "      <th>YP-111</th>\n",
       "      <th>RG-54</th>\n",
       "      <th>MC-28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BiCCA</th>\n",
       "      <td>0.218046</td>\n",
       "      <td>0.664030</td>\n",
       "      <td>0.425192</td>\n",
       "      <td>0.341557</td>\n",
       "      <td>0.535483</td>\n",
       "      <td>0.608564</td>\n",
       "      <td>0.529424</td>\n",
       "      <td>0.669920</td>\n",
       "      <td>0.265106</td>\n",
       "      <td>0.248969</td>\n",
       "      <td>0.611195</td>\n",
       "      <td>0.720961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFT</th>\n",
       "      <td>0.211617</td>\n",
       "      <td>0.681587</td>\n",
       "      <td>0.430048</td>\n",
       "      <td>0.336201</td>\n",
       "      <td>0.567407</td>\n",
       "      <td>0.616561</td>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.705907</td>\n",
       "      <td>0.269525</td>\n",
       "      <td>0.251166</td>\n",
       "      <td>0.674324</td>\n",
       "      <td>0.696039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.200728</td>\n",
       "      <td>0.675030</td>\n",
       "      <td>0.435278</td>\n",
       "      <td>0.344031</td>\n",
       "      <td>0.555848</td>\n",
       "      <td>0.603852</td>\n",
       "      <td>0.549236</td>\n",
       "      <td>0.689278</td>\n",
       "      <td>0.237874</td>\n",
       "      <td>0.216590</td>\n",
       "      <td>0.679475</td>\n",
       "      <td>0.674514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUE</th>\n",
       "      <td>0.199020</td>\n",
       "      <td>0.658349</td>\n",
       "      <td>0.419917</td>\n",
       "      <td>0.315084</td>\n",
       "      <td>0.510642</td>\n",
       "      <td>0.564960</td>\n",
       "      <td>0.527156</td>\n",
       "      <td>0.669226</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>0.373077</td>\n",
       "      <td>0.667048</td>\n",
       "      <td>0.704626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vecmap</th>\n",
       "      <td>0.226787</td>\n",
       "      <td>0.690194</td>\n",
       "      <td>0.428472</td>\n",
       "      <td>0.354032</td>\n",
       "      <td>0.570920</td>\n",
       "      <td>0.614034</td>\n",
       "      <td>0.569648</td>\n",
       "      <td>0.723163</td>\n",
       "      <td>0.272304</td>\n",
       "      <td>0.250610</td>\n",
       "      <td>0.631382</td>\n",
       "      <td>0.713618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SimVerb-3074  MEN-1146  RareWord-968  SimLex-739  MTurk-551  \\\n",
       "BiCCA       0.218046  0.664030      0.425192    0.341557   0.535483   \n",
       "MFT         0.211617  0.681587      0.430048    0.336201   0.567407   \n",
       "MSE         0.200728  0.675030      0.435278    0.344031   0.555848   \n",
       "MUE         0.199020  0.658349      0.419917    0.315084   0.510642   \n",
       "Vecmap      0.226787  0.690194      0.428472    0.354032   0.570920   \n",
       "\n",
       "        SemEval-243  WordRel-193  WordSim-193  Verb-115    YP-111     RG-54  \\\n",
       "BiCCA      0.608564     0.529424     0.669920  0.265106  0.248969  0.611195   \n",
       "MFT        0.616561     0.552381     0.705907  0.269525  0.251166  0.674324   \n",
       "MSE        0.603852     0.549236     0.689278  0.237874  0.216590  0.679475   \n",
       "MUE        0.564960     0.527156     0.669226  0.388100  0.373077  0.667048   \n",
       "Vecmap     0.614034     0.569648     0.723163  0.272304  0.250610  0.631382   \n",
       "\n",
       "           MC-28  \n",
       "BiCCA   0.720961  \n",
       "MFT     0.696039  \n",
       "MSE     0.674514  \n",
       "MUE     0.704626  \n",
       "Vecmap  0.713618  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intrinsic_metrics = pandas.DataFrame({ model_name : [spearmanr(*calculate_cosines(read_csv(dataset),\n",
    "                                                                                  en_model,\n",
    "                                                                                  ru_model,\n",
    "                                                                                  verbose=False))[0]\n",
    "                                                     for dataset, _ in english_russian_word_similarity]\n",
    "                                      for en_model, ru_model, model_name in models},\n",
    "                                     index=[name for _, name in english_russian_word_similarity]).transpose()\n",
    "intrinsic_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:16:44.889413Z",
     "start_time": "2018-02-21T14:16:44.458086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SimVerb-3074</th>\n",
       "      <th>MEN-1146</th>\n",
       "      <th>RareWord-968</th>\n",
       "      <th>SimLex-739</th>\n",
       "      <th>MTurk-551</th>\n",
       "      <th>SemEval-243</th>\n",
       "      <th>WordRel-193</th>\n",
       "      <th>WordSim-193</th>\n",
       "      <th>Verb-115</th>\n",
       "      <th>YP-111</th>\n",
       "      <th>RG-54</th>\n",
       "      <th>MC-28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BiCCA</th>\n",
       "      <td>0.581498</td>\n",
       "      <td>-0.760620</td>\n",
       "      <td>-0.453656</td>\n",
       "      <td>0.233732</td>\n",
       "      <td>-0.501510</td>\n",
       "      <td>0.330913</td>\n",
       "      <td>-0.917210</td>\n",
       "      <td>-0.924999</td>\n",
       "      <td>-0.367849</td>\n",
       "      <td>-0.316022</td>\n",
       "      <td>-1.389277</td>\n",
       "      <td>1.057550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFT</th>\n",
       "      <td>0.032267</td>\n",
       "      <td>0.600957</td>\n",
       "      <td>0.397068</td>\n",
       "      <td>-0.137127</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.710596</td>\n",
       "      <td>0.387008</td>\n",
       "      <td>0.617614</td>\n",
       "      <td>-0.292151</td>\n",
       "      <td>-0.279702</td>\n",
       "      <td>0.724576</td>\n",
       "      <td>-0.328937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>-0.898082</td>\n",
       "      <td>0.092441</td>\n",
       "      <td>1.313112</td>\n",
       "      <td>0.405102</td>\n",
       "      <td>0.310552</td>\n",
       "      <td>0.107188</td>\n",
       "      <td>0.208338</td>\n",
       "      <td>-0.095201</td>\n",
       "      <td>-0.834276</td>\n",
       "      <td>-0.851369</td>\n",
       "      <td>0.897082</td>\n",
       "      <td>-1.526436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUE</th>\n",
       "      <td>-1.043980</td>\n",
       "      <td>-1.201197</td>\n",
       "      <td>-1.377543</td>\n",
       "      <td>-1.599298</td>\n",
       "      <td>-1.491999</td>\n",
       "      <td>-1.739318</td>\n",
       "      <td>-1.046079</td>\n",
       "      <td>-0.954741</td>\n",
       "      <td>1.738825</td>\n",
       "      <td>1.735976</td>\n",
       "      <td>0.480946</td>\n",
       "      <td>0.148792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vecmap</th>\n",
       "      <td>1.328297</td>\n",
       "      <td>1.268420</td>\n",
       "      <td>0.121019</td>\n",
       "      <td>1.097590</td>\n",
       "      <td>0.911527</td>\n",
       "      <td>0.590621</td>\n",
       "      <td>1.367942</td>\n",
       "      <td>1.357327</td>\n",
       "      <td>-0.244549</td>\n",
       "      <td>-0.288884</td>\n",
       "      <td>-0.713326</td>\n",
       "      <td>0.649032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SimVerb-3074  MEN-1146  RareWord-968  SimLex-739  MTurk-551  \\\n",
       "BiCCA       0.581498 -0.760620     -0.453656    0.233732  -0.501510   \n",
       "MFT         0.032267  0.600957      0.397068   -0.137127   0.771429   \n",
       "MSE        -0.898082  0.092441      1.313112    0.405102   0.310552   \n",
       "MUE        -1.043980 -1.201197     -1.377543   -1.599298  -1.491999   \n",
       "Vecmap      1.328297  1.268420      0.121019    1.097590   0.911527   \n",
       "\n",
       "        SemEval-243  WordRel-193  WordSim-193  Verb-115    YP-111     RG-54  \\\n",
       "BiCCA      0.330913    -0.917210    -0.924999 -0.367849 -0.316022 -1.389277   \n",
       "MFT        0.710596     0.387008     0.617614 -0.292151 -0.279702  0.724576   \n",
       "MSE        0.107188     0.208338    -0.095201 -0.834276 -0.851369  0.897082   \n",
       "MUE       -1.739318    -1.046079    -0.954741  1.738825  1.735976  0.480946   \n",
       "Vecmap     0.590621     1.367942     1.357327 -0.244549 -0.288884 -0.713326   \n",
       "\n",
       "           MC-28  \n",
       "BiCCA   1.057550  \n",
       "MFT    -0.328937  \n",
       "MSE    -1.526436  \n",
       "MUE     0.148792  \n",
       "Vecmap  0.649032  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intrinsic_metrics_norm = (intrinsic_metrics - intrinsic_metrics.mean(0)) / intrinsic_metrics.std(0)\n",
    "intrinsic_metrics_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:16:44.922141Z",
     "start_time": "2018-02-21T14:16:44.891629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SimVerb-3074</th>\n",
       "      <th>MEN-1146</th>\n",
       "      <th>RareWord-968</th>\n",
       "      <th>SimLex-739</th>\n",
       "      <th>MTurk-551</th>\n",
       "      <th>SemEval-243</th>\n",
       "      <th>WordRel-193</th>\n",
       "      <th>WordSim-193</th>\n",
       "      <th>Verb-115</th>\n",
       "      <th>YP-111</th>\n",
       "      <th>RG-54</th>\n",
       "      <th>MC-28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BiCCA</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFT</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUE</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vecmap</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SimVerb-3074  MEN-1146  RareWord-968  SimLex-739  MTurk-551  \\\n",
       "BiCCA              4         4             4           4          4   \n",
       "MFT                3         1             1           2          1   \n",
       "MSE                2         3             5           1          3   \n",
       "MUE                1         2             2           3          2   \n",
       "Vecmap             5         5             3           5          5   \n",
       "\n",
       "        SemEval-243  WordRel-193  WordSim-193  Verb-115  YP-111  RG-54  MC-28  \n",
       "BiCCA             4            4            4         3       3      1      3  \n",
       "MFT               3            1            1         1       1      5      2  \n",
       "MSE               1            3            3         2       5      4      4  \n",
       "MUE               5            2            2         5       2      2      5  \n",
       "Vecmap            2            5            5         4       4      3      1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intrinsic_metrics_order = intrinsic_metrics.apply(lambda s: s.argsort() + 1)\n",
    "intrinsic_metrics_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_on_word_translation(model_en, model_ru, k=5):\n",
    "    count = 0\n",
    "\n",
    "    for src_word, trg_word in en_ru_dict.items():\n",
    "        similar_words = model_ru.similar_by_vector(model_en[src_word], k)\n",
    "        if trg_word in [word[0] for word in similar_words]:\n",
    "            count += 1\n",
    "    return count/len(en_ru_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-277d8d0db5a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_ru\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} p@{}: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_on_word_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_ru\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-182e9a88d0a4>\u001b[0m in \u001b[0;36mevaluate_on_word_translation\u001b[0;34m(model_en, model_ru, k)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msrc_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_word\u001b[0m \u001b[0;32min\u001b[0m \u001b[0men_ru_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msimilar_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ru\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilar_by_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_en\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrc_word\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrg_word\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimilar_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36msimilar_by_vector\u001b[0;34m(self, vector, topn, restrict_vocab)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \"\"\"\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwmdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0mlimited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0norm\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrestrict_vocab\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimited\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for model_en, model_ru, name in models:\n",
    "    for k in [1, 5, 10]:\n",
    "        results.append('{} p@{}: {}'.format(name, k, evaluate_on_word_translation(model_en, model_ru, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T10:47:38.687775Z",
     "start_time": "2018-02-22T10:47:38.675023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WT p@1</th>\n",
       "      <th>WT p@10</th>\n",
       "      <th>WT p@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Vecmap</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUE</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BiCCA</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFT</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WT p@1  WT p@10  WT p@5\n",
       "Vecmap    0.32     0.59    0.52\n",
       "MSE       0.31     0.61    0.54\n",
       "MUE       0.17     0.46    0.35\n",
       "BiCCA     0.29     0.56    0.49\n",
       "MFT       0.21     0.45    0.38"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_translation_metrics = pandas.DataFrame({'WT p@1' :  [0.32, 0.31, 0.17, 0.29, 0.21],\n",
    "                                             'WT p@5' :  [0.52, 0.54, 0.35, 0.49, 0.38],\n",
    "                                             'WT p@10' : [0.59, 0.61, 0.46, 0.56, 0.45],},\n",
    "                                            index=['Vecmap', 'MSE', 'MUE', 'BiCCA', 'MFT'])\n",
    "word_translation_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['Vecmap p@1: 0.32002815909890886',\n",
    " 'Vecmap p@5: 0.5231725918103954',\n",
    " 'Vecmap p@10: 0.5899800539716062',\n",
    " 'MSE p@1: 0.3146779303062302',\n",
    " 'MSE p@5: 0.5372990730963276',\n",
    " 'MSE p@10: 0.6117798897101959',\n",
    " 'MUE p@1: 0.16843834330634752',\n",
    " 'MUE p@5: 0.34640384841018423',\n",
    " 'MUE p@10: 0.42592983691188546',\n",
    " 'BiCCA p@1: 0.2930658218936994',\n",
    " 'BiCCA p@5: 0.49097735539129417',\n",
    " 'BiCCA p@10: 0.5556728851343423']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate extrinsic scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T10:47:47.541779Z",
     "start_time": "2018-02-22T10:47:46.802958Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_vec_simple(tokens, num_features, model):\n",
    "    result = np.zeros(shape=(num_features), dtype='float32')\n",
    "    norm = 0\n",
    "    for word in tokens:\n",
    "        if word in model.wv.vocab:\n",
    "            result += model[word]\n",
    "            norm += 1\n",
    "    if norm > 0:\n",
    "        result /= norm\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_feature_vec(tokens, num_features, model):\n",
    "    token_idx = [model.vocab[w].index for w in tokens if w in model.wv.vocab]\n",
    "    if len(token_idx) > 0:\n",
    "        return np.mean(model.syn0[token_idx], axis=0)\n",
    "    else:\n",
    "        return np.zeros(num_features, dtype='float32')\n",
    "\n",
    "\n",
    "def get_vectors(model_en, model_ru, dataset):\n",
    "    eng_vectors = []\n",
    "    rus_vectors = []\n",
    "    common_vectors = []\n",
    "    \n",
    "    for i in dataset.index:\n",
    "        eng_vec = get_feature_vec([word.lower() for word in alpha_tokenizer.tokenize(dataset.loc[i, 'sentence1'])], \n",
    "                                   model_en.vector_size, model_en)\n",
    "        eng_vectors.append(eng_vec)\n",
    "        rus_vec = get_feature_vec([word.lower() for word in alpha_tokenizer.tokenize(dataset.loc[i, 'sentence2'])],\n",
    "                                   model_ru.vector_size, model_ru)\n",
    "        rus_vectors.append(rus_vec)\n",
    "        common_vectors.append(np.hstack((eng_vec, rus_vec)))\n",
    "#     eng_vectors = np.array(eng_vectors)\n",
    "#     rus_vectors = np.array(rus_vectors)\n",
    "    return np.array(eng_vectors), np.array(rus_vectors), np.array(common_vectors)\n",
    "\n",
    "\n",
    "METRICS = (\n",
    "    ('f1', f1_score),\n",
    "    ('p', precision_score),\n",
    "    ('r', recall_score),\n",
    ")\n",
    "\n",
    "def evaluate_extrinsic(embeddings1, embeddings2, classifier_ctor, splits, metrics=METRICS, float_target=True):\n",
    "    result = []\n",
    "    for train_data, test_data in splits:\n",
    "        _, _, X_train  = get_vectors(embeddings1, embeddings2, train_data)\n",
    "        _, _, X_test  = get_vectors(embeddings1, embeddings2, test_data)\n",
    "        Y_train = train_data.is_paraphrase.values\n",
    "        Y_test = test_data.is_paraphrase.values\n",
    "        if float_target:\n",
    "            Y_train = Y_train.astype('float32')\n",
    "            Y_test = Y_test.astype('float32')\n",
    "\n",
    "        clf = classifier_ctor()\n",
    "        \n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred = np.where(clf.predict_proba(X_test) > 0.5, 1, 0)\n",
    "        if pred.shape[1] > 1:\n",
    "            pred = pred[:, 1]\n",
    "\n",
    "        result.append({ metric_name : metric_func(pred, Y_test)\n",
    "                       for metric_name, metric_func in metrics})\n",
    "    return pandas.DataFrame(result).describe().loc[['mean', 'std']]\n",
    "\n",
    "\n",
    "def vectors2cosine(vecs):\n",
    "    dims = vecs.shape[1] // 2\n",
    "    result = np.array([cosine(vecs[i, :dims], vecs[i, dims:]) for i in range(vecs.shape[0])])\n",
    "    result[np.isnan(result)] = 1.0\n",
    "    return np.expand_dims(result, 1)\n",
    "\n",
    "\n",
    "def make_cosine_logreg_ctor(vector_size):\n",
    "    def _f():\n",
    "        return Pipeline((('cos', FunctionTransformer(vectors2cosine)),\n",
    "                         ('clf', LogisticRegressionCV())))\n",
    "    return _f\n",
    "\n",
    "\n",
    "class BilinearModel(nn.Module):\n",
    "    def __init__(self, vector_size):\n",
    "        super(BilinearModel, self).__init__()\n",
    "        self.vector_size = vector_size\n",
    "        self.compare = nn.Bilinear(self.vector_size, self.vector_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"x.size = (Batch, Dim)\"\"\"\n",
    "        a = x[:, :self.vector_size].float()\n",
    "        b = x[:, self.vector_size:].float()\n",
    "        return F.sigmoid(self.compare(a, b))\n",
    "\n",
    "\n",
    "def make_bilinear_model_ctor(vector_size):\n",
    "    def _f():\n",
    "        return skorch.NeuralNet(BilinearModel,\n",
    "                                module__vector_size=vector_size,\n",
    "                                optimizer=torch.optim.Adam,\n",
    "                                lr=0.1,\n",
    "                                criterion=nn.BCELoss,\n",
    "                                max_epochs=100,\n",
    "                                verbose=0)\n",
    "    return _f\n",
    "\n",
    "\n",
    "class ProjCosineModel(nn.Module):\n",
    "    def __init__(self, vector_size, proj_size=100, proj_act=lambda x: x):\n",
    "        super(ProjCosineModel, self).__init__()\n",
    "        self.vector_size = vector_size\n",
    "        self.proj = nn.Linear(vector_size, proj_size)\n",
    "        self.proj_act = proj_act\n",
    "        self.out = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"x.size = (Batch, Dim)\"\"\"\n",
    "        a = x[:, :self.vector_size].float()\n",
    "        b = x[:, self.vector_size:].float()\n",
    "        ap = self.proj_act(self.proj(a))\n",
    "        bp = self.proj_act(self.proj(b))\n",
    "        return F.sigmoid(self.out(F.cosine_similarity(ap, bp).unsqueeze(-1)))\n",
    "\n",
    "\n",
    "def make_proj_cosine_model_ctor(vector_size):\n",
    "    def _f():\n",
    "        return skorch.NeuralNet(ProjCosineModel,\n",
    "                                module__vector_size=vector_size,\n",
    "                                optimizer=torch.optim.Adam,\n",
    "                                lr=0.1,\n",
    "                                criterion=nn.BCELoss,\n",
    "                                max_epochs=100,\n",
    "                                verbose=0)\n",
    "    return _f\n",
    "\n",
    "\n",
    "PAIR_CLASSIFIERS = (\n",
    "    ('cos lr', make_cosine_logreg_ctor),\n",
    "#     ('bilinear', make_bilinear_model_ctor),\n",
    "#     ('proj cos', make_proj_cosine_model_ctor),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T06:49:18.130916Z",
     "start_time": "2018-02-22T06:49:18.105807Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %prun -s cumulative evaluate_extrinsic(bi_cca_en, bi_cca_ru, make_cosine_logreg_ctor(bi_cca_en.vector_size), yandex_train_test_data[:1])\n",
    "# %lprun -f get_vectors evaluate_extrinsic(bi_cca_en, bi_cca_ru, make_cosine_logreg_ctor(bi_cca_en.vector_size), strict_train_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T09:56:05.880399Z",
     "start_time": "2018-02-22T06:49:34.332522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2018, 2, 22, 6, 49, 34, 349588), 'Vecmap', 'cos lr', 'para strict')\n",
      "(datetime.datetime(2018, 2, 22, 6, 49, 44, 53490), 'Vecmap', 'cos lr', 'yandex wmt')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2018, 2, 22, 7, 25, 49, 44497), 'MSE', 'cos lr', 'para strict')\n",
      "(datetime.datetime(2018, 2, 22, 7, 26, 17, 180220), 'MSE', 'cos lr', 'yandex wmt')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2018, 2, 22, 8, 0, 57, 679144), 'MUE', 'cos lr', 'para strict')\n",
      "(datetime.datetime(2018, 2, 22, 8, 1, 25, 491739), 'MUE', 'cos lr', 'yandex wmt')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2018, 2, 22, 8, 36, 6, 942882), 'BiCCA', 'cos lr', 'para strict')\n",
      "(datetime.datetime(2018, 2, 22, 8, 37, 52, 996348), 'BiCCA', 'cos lr', 'yandex wmt')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2018, 2, 22, 9, 16, 10, 635867), 'MFT', 'cos lr', 'para strict')\n",
      "(datetime.datetime(2018, 2, 22, 9, 17, 1, 277186), 'MFT', 'cos lr', 'yandex wmt')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>para strict</th>\n",
       "      <th>yandex wmt</th>\n",
       "      <th>para strict</th>\n",
       "      <th>yandex wmt</th>\n",
       "      <th>para strict</th>\n",
       "      <th>yandex wmt</th>\n",
       "      <th>para strict</th>\n",
       "      <th>yandex wmt</th>\n",
       "      <th>para strict</th>\n",
       "      <th>yandex wmt</th>\n",
       "      <th>para strict</th>\n",
       "      <th>yandex wmt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1</th>\n",
       "      <th>p</th>\n",
       "      <th>p</th>\n",
       "      <th>p</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>r</th>\n",
       "      <th>r</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BiCCA</th>\n",
       "      <th>cos lr</th>\n",
       "      <td>0.827839</td>\n",
       "      <td>0.596666</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.002568</td>\n",
       "      <td>0.839732</td>\n",
       "      <td>0.633775</td>\n",
       "      <td>0.030854</td>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.816629</td>\n",
       "      <td>0.563749</td>\n",
       "      <td>0.004983</td>\n",
       "      <td>0.003604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFT</th>\n",
       "      <th>cos lr</th>\n",
       "      <td>0.857646</td>\n",
       "      <td>0.591429</td>\n",
       "      <td>0.012919</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>0.868360</td>\n",
       "      <td>0.637347</td>\n",
       "      <td>0.016867</td>\n",
       "      <td>0.010316</td>\n",
       "      <td>0.847261</td>\n",
       "      <td>0.551756</td>\n",
       "      <td>0.011988</td>\n",
       "      <td>0.002603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <th>cos lr</th>\n",
       "      <td>0.816271</td>\n",
       "      <td>0.553240</td>\n",
       "      <td>0.009983</td>\n",
       "      <td>0.012097</td>\n",
       "      <td>0.830451</td>\n",
       "      <td>0.594194</td>\n",
       "      <td>0.027310</td>\n",
       "      <td>0.033620</td>\n",
       "      <td>0.803408</td>\n",
       "      <td>0.518268</td>\n",
       "      <td>0.023425</td>\n",
       "      <td>0.004754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUE</th>\n",
       "      <th>cos lr</th>\n",
       "      <td>0.769184</td>\n",
       "      <td>0.449030</td>\n",
       "      <td>0.014490</td>\n",
       "      <td>0.024467</td>\n",
       "      <td>0.791503</td>\n",
       "      <td>0.393101</td>\n",
       "      <td>0.021002</td>\n",
       "      <td>0.040006</td>\n",
       "      <td>0.748814</td>\n",
       "      <td>0.526094</td>\n",
       "      <td>0.029241</td>\n",
       "      <td>0.005887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vecmap</th>\n",
       "      <th>cos lr</th>\n",
       "      <td>0.844189</td>\n",
       "      <td>0.569427</td>\n",
       "      <td>0.012538</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.857283</td>\n",
       "      <td>0.604805</td>\n",
       "      <td>0.033153</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.832279</td>\n",
       "      <td>0.538010</td>\n",
       "      <td>0.017262</td>\n",
       "      <td>0.002044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              para strict yandex wmt para strict yandex wmt para strict  \\\n",
       "                       f1         f1          f1         f1           p   \n",
       "                     mean       mean         std        std        mean   \n",
       "BiCCA  cos lr    0.827839   0.596666    0.015713   0.002568    0.839732   \n",
       "MFT    cos lr    0.857646   0.591429    0.012919   0.003073    0.868360   \n",
       "MSE    cos lr    0.816271   0.553240    0.009983   0.012097    0.830451   \n",
       "MUE    cos lr    0.769184   0.449030    0.014490   0.024467    0.791503   \n",
       "Vecmap cos lr    0.844189   0.569427    0.012538   0.002997    0.857283   \n",
       "\n",
       "              yandex wmt para strict yandex wmt para strict yandex wmt  \\\n",
       "                       p           p          p           r          r   \n",
       "                    mean         std        std        mean       mean   \n",
       "BiCCA  cos lr   0.633775    0.030854   0.010060    0.816629   0.563749   \n",
       "MFT    cos lr   0.637347    0.016867   0.010316    0.847261   0.551756   \n",
       "MSE    cos lr   0.594194    0.027310   0.033620    0.803408   0.518268   \n",
       "MUE    cos lr   0.393101    0.021002   0.040006    0.748814   0.526094   \n",
       "Vecmap cos lr   0.604805    0.033153   0.008575    0.832279   0.538010   \n",
       "\n",
       "              para strict yandex wmt  \n",
       "                        r          r  \n",
       "                      std        std  \n",
       "BiCCA  cos lr    0.004983   0.003604  \n",
       "MFT    cos lr    0.011988   0.002603  \n",
       "MSE    cos lr    0.023425   0.004754  \n",
       "MUE    cos lr    0.029241   0.005887  \n",
       "Vecmap cos lr    0.017262   0.002044  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrinsic_metrics = []\n",
    "extrinsic_metrics_idx = []\n",
    "for en_model, ru_model, model_name in models:\n",
    "    for pair_clf_name, pair_clf_ctor_maker in PAIR_CLASSIFIERS:\n",
    "        for dataset_name, dataset_splits in EXTRINSIC_DATASETS:\n",
    "            print((datetime.datetime.now(), model_name, pair_clf_name, dataset_name))\n",
    "            extrinsic_metrics_idx.append((model_name, pair_clf_name, dataset_name))\n",
    "            extrinsic_metrics.append(evaluate_extrinsic(en_model,\n",
    "                                                        ru_model,\n",
    "                                                        pair_clf_ctor_maker(en_model.vector_size),\n",
    "                                                        dataset_splits))\n",
    "\n",
    "extrinsic_metrics = pandas.concat(extrinsic_metrics, keys=extrinsic_metrics_idx) \\\n",
    "    .unstack().unstack().swaplevel(0, -1, 1).swaplevel(1, -1, 1)\n",
    "extrinsic_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T09:56:46.539191Z",
     "start_time": "2018-02-22T09:56:46.440641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>para strict f1</th>\n",
       "      <th>yandex wmt f1</th>\n",
       "      <th>para strict p</th>\n",
       "      <th>yandex wmt p</th>\n",
       "      <th>para strict r</th>\n",
       "      <th>yandex wmt r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BiCCA</th>\n",
       "      <td>0.827839</td>\n",
       "      <td>0.596666</td>\n",
       "      <td>0.839732</td>\n",
       "      <td>0.633775</td>\n",
       "      <td>0.816629</td>\n",
       "      <td>0.563749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFT</th>\n",
       "      <td>0.857646</td>\n",
       "      <td>0.591429</td>\n",
       "      <td>0.868360</td>\n",
       "      <td>0.637347</td>\n",
       "      <td>0.847261</td>\n",
       "      <td>0.551756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.816271</td>\n",
       "      <td>0.553240</td>\n",
       "      <td>0.830451</td>\n",
       "      <td>0.594194</td>\n",
       "      <td>0.803408</td>\n",
       "      <td>0.518268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUE</th>\n",
       "      <td>0.769184</td>\n",
       "      <td>0.449030</td>\n",
       "      <td>0.791503</td>\n",
       "      <td>0.393101</td>\n",
       "      <td>0.748814</td>\n",
       "      <td>0.526094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vecmap</th>\n",
       "      <td>0.844189</td>\n",
       "      <td>0.569427</td>\n",
       "      <td>0.857283</td>\n",
       "      <td>0.604805</td>\n",
       "      <td>0.832279</td>\n",
       "      <td>0.538010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        para strict f1  yandex wmt f1  para strict p  yandex wmt p  \\\n",
       "BiCCA         0.827839       0.596666       0.839732      0.633775   \n",
       "MFT           0.857646       0.591429       0.868360      0.637347   \n",
       "MSE           0.816271       0.553240       0.830451      0.594194   \n",
       "MUE           0.769184       0.449030       0.791503      0.393101   \n",
       "Vecmap        0.844189       0.569427       0.857283      0.604805   \n",
       "\n",
       "        para strict r  yandex wmt r  \n",
       "BiCCA        0.816629      0.563749  \n",
       "MFT          0.847261      0.551756  \n",
       "MSE          0.803408      0.518268  \n",
       "MUE          0.748814      0.526094  \n",
       "Vecmap       0.832279      0.538010  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrinsic_metrics_flat = extrinsic_metrics.copy()\n",
    "extrinsic_metrics_flat.drop('std', axis=1, level=2, inplace=True)\n",
    "extrinsic_metrics_flat.columns = [' '.join(t[:-1]) for t in extrinsic_metrics_flat.columns]\n",
    "extrinsic_metrics_flat.index = extrinsic_metrics_flat.index.get_level_values(0)\n",
    "extrinsic_metrics_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T11:41:22.101792Z",
     "start_time": "2018-02-22T11:41:22.011030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SimVerb-3074</th>\n",
       "      <th>MEN-1146</th>\n",
       "      <th>RareWord-968</th>\n",
       "      <th>SimLex-739</th>\n",
       "      <th>MTurk-551</th>\n",
       "      <th>SemEval-243</th>\n",
       "      <th>WordRel-193</th>\n",
       "      <th>WordSim-193</th>\n",
       "      <th>Verb-115</th>\n",
       "      <th>YP-111</th>\n",
       "      <th>RG-54</th>\n",
       "      <th>MC-28</th>\n",
       "      <th>WT p@1</th>\n",
       "      <th>WT p@10</th>\n",
       "      <th>WT p@5</th>\n",
       "      <th>Our dataset, f1</th>\n",
       "      <th>EN-RU WMT, f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BiCCA</th>\n",
       "      <td>0.218046</td>\n",
       "      <td>0.664030</td>\n",
       "      <td>0.425192</td>\n",
       "      <td>0.341557</td>\n",
       "      <td>0.535483</td>\n",
       "      <td>0.608564</td>\n",
       "      <td>0.529424</td>\n",
       "      <td>0.669920</td>\n",
       "      <td>0.265106</td>\n",
       "      <td>0.248969</td>\n",
       "      <td>0.611195</td>\n",
       "      <td>0.720961</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.827839</td>\n",
       "      <td>0.596666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFT</th>\n",
       "      <td>0.211617</td>\n",
       "      <td>0.681587</td>\n",
       "      <td>0.430048</td>\n",
       "      <td>0.336201</td>\n",
       "      <td>0.567407</td>\n",
       "      <td>0.616561</td>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.705907</td>\n",
       "      <td>0.269525</td>\n",
       "      <td>0.251166</td>\n",
       "      <td>0.674324</td>\n",
       "      <td>0.696039</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.857646</td>\n",
       "      <td>0.591429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.200728</td>\n",
       "      <td>0.675030</td>\n",
       "      <td>0.435278</td>\n",
       "      <td>0.344031</td>\n",
       "      <td>0.555848</td>\n",
       "      <td>0.603852</td>\n",
       "      <td>0.549236</td>\n",
       "      <td>0.689278</td>\n",
       "      <td>0.237874</td>\n",
       "      <td>0.216590</td>\n",
       "      <td>0.679475</td>\n",
       "      <td>0.674514</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.816271</td>\n",
       "      <td>0.553240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUE</th>\n",
       "      <td>0.199020</td>\n",
       "      <td>0.658349</td>\n",
       "      <td>0.419917</td>\n",
       "      <td>0.315084</td>\n",
       "      <td>0.510642</td>\n",
       "      <td>0.564960</td>\n",
       "      <td>0.527156</td>\n",
       "      <td>0.669226</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>0.373077</td>\n",
       "      <td>0.667048</td>\n",
       "      <td>0.704626</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.769184</td>\n",
       "      <td>0.449030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vecmap</th>\n",
       "      <td>0.226787</td>\n",
       "      <td>0.690194</td>\n",
       "      <td>0.428472</td>\n",
       "      <td>0.354032</td>\n",
       "      <td>0.570920</td>\n",
       "      <td>0.614034</td>\n",
       "      <td>0.569648</td>\n",
       "      <td>0.723163</td>\n",
       "      <td>0.272304</td>\n",
       "      <td>0.250610</td>\n",
       "      <td>0.631382</td>\n",
       "      <td>0.713618</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.844189</td>\n",
       "      <td>0.569427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SimVerb-3074  MEN-1146  RareWord-968  SimLex-739  MTurk-551  \\\n",
       "BiCCA       0.218046  0.664030      0.425192    0.341557   0.535483   \n",
       "MFT         0.211617  0.681587      0.430048    0.336201   0.567407   \n",
       "MSE         0.200728  0.675030      0.435278    0.344031   0.555848   \n",
       "MUE         0.199020  0.658349      0.419917    0.315084   0.510642   \n",
       "Vecmap      0.226787  0.690194      0.428472    0.354032   0.570920   \n",
       "\n",
       "        SemEval-243  WordRel-193  WordSim-193  Verb-115    YP-111     RG-54  \\\n",
       "BiCCA      0.608564     0.529424     0.669920  0.265106  0.248969  0.611195   \n",
       "MFT        0.616561     0.552381     0.705907  0.269525  0.251166  0.674324   \n",
       "MSE        0.603852     0.549236     0.689278  0.237874  0.216590  0.679475   \n",
       "MUE        0.564960     0.527156     0.669226  0.388100  0.373077  0.667048   \n",
       "Vecmap     0.614034     0.569648     0.723163  0.272304  0.250610  0.631382   \n",
       "\n",
       "           MC-28  WT p@1  WT p@10  WT p@5  Our dataset, f1  EN-RU WMT, f1  \n",
       "BiCCA   0.720961    0.29     0.56    0.49         0.827839       0.596666  \n",
       "MFT     0.696039    0.21     0.45    0.38         0.857646       0.591429  \n",
       "MSE     0.674514    0.31     0.61    0.54         0.816271       0.553240  \n",
       "MUE     0.704626    0.17     0.46    0.35         0.769184       0.449030  \n",
       "Vecmap  0.713618    0.32     0.59    0.52         0.844189       0.569427  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SimVerb-3074</th>\n",
       "      <th>MEN-1146</th>\n",
       "      <th>RareWord-968</th>\n",
       "      <th>SimLex-739</th>\n",
       "      <th>MTurk-551</th>\n",
       "      <th>SemEval-243</th>\n",
       "      <th>WordRel-193</th>\n",
       "      <th>WordSim-193</th>\n",
       "      <th>Verb-115</th>\n",
       "      <th>YP-111</th>\n",
       "      <th>RG-54</th>\n",
       "      <th>MC-28</th>\n",
       "      <th>WT p@1</th>\n",
       "      <th>WT p@10</th>\n",
       "      <th>WT p@5</th>\n",
       "      <th>Our dataset, f1</th>\n",
       "      <th>EN-RU WMT, f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BiCCA</th>\n",
       "      <td>0.581498</td>\n",
       "      <td>-0.760620</td>\n",
       "      <td>-0.453656</td>\n",
       "      <td>0.233732</td>\n",
       "      <td>-0.501510</td>\n",
       "      <td>0.330913</td>\n",
       "      <td>-0.917210</td>\n",
       "      <td>-0.924999</td>\n",
       "      <td>-0.367849</td>\n",
       "      <td>-0.316022</td>\n",
       "      <td>-1.389277</td>\n",
       "      <td>1.057550</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.349632</td>\n",
       "      <td>0.397125</td>\n",
       "      <td>0.141730</td>\n",
       "      <td>0.743635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFT</th>\n",
       "      <td>0.032267</td>\n",
       "      <td>0.600957</td>\n",
       "      <td>0.397068</td>\n",
       "      <td>-0.137127</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.710596</td>\n",
       "      <td>0.387008</td>\n",
       "      <td>0.617614</td>\n",
       "      <td>-0.292151</td>\n",
       "      <td>-0.279702</td>\n",
       "      <td>0.724576</td>\n",
       "      <td>-0.328937</td>\n",
       "      <td>-0.753778</td>\n",
       "      <td>-1.129579</td>\n",
       "      <td>-0.887691</td>\n",
       "      <td>1.019328</td>\n",
       "      <td>0.656529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>-0.898082</td>\n",
       "      <td>0.092441</td>\n",
       "      <td>1.313112</td>\n",
       "      <td>0.405102</td>\n",
       "      <td>0.310552</td>\n",
       "      <td>0.107188</td>\n",
       "      <td>0.208338</td>\n",
       "      <td>-0.095201</td>\n",
       "      <td>-0.834276</td>\n",
       "      <td>-0.851369</td>\n",
       "      <td>0.897082</td>\n",
       "      <td>-1.526436</td>\n",
       "      <td>0.753778</td>\n",
       "      <td>1.022000</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>-0.198887</td>\n",
       "      <td>0.021317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUE</th>\n",
       "      <td>-1.043980</td>\n",
       "      <td>-1.201197</td>\n",
       "      <td>-1.377543</td>\n",
       "      <td>-1.599298</td>\n",
       "      <td>-1.491999</td>\n",
       "      <td>-1.739318</td>\n",
       "      <td>-1.046079</td>\n",
       "      <td>-0.954741</td>\n",
       "      <td>1.738825</td>\n",
       "      <td>1.735976</td>\n",
       "      <td>0.480946</td>\n",
       "      <td>0.148792</td>\n",
       "      <td>-1.356801</td>\n",
       "      <td>-0.995106</td>\n",
       "      <td>-1.238095</td>\n",
       "      <td>-1.585269</td>\n",
       "      <td>-1.712044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vecmap</th>\n",
       "      <td>1.328297</td>\n",
       "      <td>1.268420</td>\n",
       "      <td>0.121019</td>\n",
       "      <td>1.097590</td>\n",
       "      <td>0.911527</td>\n",
       "      <td>0.590621</td>\n",
       "      <td>1.367942</td>\n",
       "      <td>1.357327</td>\n",
       "      <td>-0.244549</td>\n",
       "      <td>-0.288884</td>\n",
       "      <td>-0.713326</td>\n",
       "      <td>0.649032</td>\n",
       "      <td>0.904534</td>\n",
       "      <td>0.753053</td>\n",
       "      <td>0.747529</td>\n",
       "      <td>0.623098</td>\n",
       "      <td>0.290562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SimVerb-3074  MEN-1146  RareWord-968  SimLex-739  MTurk-551  \\\n",
       "BiCCA       0.581498 -0.760620     -0.453656    0.233732  -0.501510   \n",
       "MFT         0.032267  0.600957      0.397068   -0.137127   0.771429   \n",
       "MSE        -0.898082  0.092441      1.313112    0.405102   0.310552   \n",
       "MUE        -1.043980 -1.201197     -1.377543   -1.599298  -1.491999   \n",
       "Vecmap      1.328297  1.268420      0.121019    1.097590   0.911527   \n",
       "\n",
       "        SemEval-243  WordRel-193  WordSim-193  Verb-115    YP-111     RG-54  \\\n",
       "BiCCA      0.330913    -0.917210    -0.924999 -0.367849 -0.316022 -1.389277   \n",
       "MFT        0.710596     0.387008     0.617614 -0.292151 -0.279702  0.724576   \n",
       "MSE        0.107188     0.208338    -0.095201 -0.834276 -0.851369  0.897082   \n",
       "MUE       -1.739318    -1.046079    -0.954741  1.738825  1.735976  0.480946   \n",
       "Vecmap     0.590621     1.367942     1.357327 -0.244549 -0.288884 -0.713326   \n",
       "\n",
       "           MC-28    WT p@1   WT p@10    WT p@5  Our dataset, f1  EN-RU WMT, f1  \n",
       "BiCCA   1.057550  0.452267  0.349632  0.397125         0.141730       0.743635  \n",
       "MFT    -0.328937 -0.753778 -1.129579 -0.887691         1.019328       0.656529  \n",
       "MSE    -1.526436  0.753778  1.022000  0.981132        -0.198887       0.021317  \n",
       "MUE     0.148792 -1.356801 -0.995106 -1.238095        -1.585269      -1.712044  \n",
       "Vecmap  0.649032  0.904534  0.753053  0.747529         0.623098       0.290562  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SimVerb-3074</th>\n",
       "      <th>MEN-1146</th>\n",
       "      <th>RareWord-968</th>\n",
       "      <th>SimLex-739</th>\n",
       "      <th>MTurk-551</th>\n",
       "      <th>SemEval-243</th>\n",
       "      <th>WordRel-193</th>\n",
       "      <th>WordSim-193</th>\n",
       "      <th>Verb-115</th>\n",
       "      <th>YP-111</th>\n",
       "      <th>RG-54</th>\n",
       "      <th>MC-28</th>\n",
       "      <th>WT p@1</th>\n",
       "      <th>WT p@10</th>\n",
       "      <th>WT p@5</th>\n",
       "      <th>Our dataset, f1</th>\n",
       "      <th>EN-RU WMT, f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BiCCA</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFT</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUE</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vecmap</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SimVerb-3074  MEN-1146  RareWord-968  SimLex-739  MTurk-551  \\\n",
       "BiCCA              2         4             4           3          4   \n",
       "MFT                3         2             2           4          2   \n",
       "MSE                4         3             1           2          3   \n",
       "MUE                5         5             5           5          5   \n",
       "Vecmap             1         1             3           1          1   \n",
       "\n",
       "        SemEval-243  WordRel-193  WordSim-193  Verb-115  YP-111  RG-54  MC-28  \\\n",
       "BiCCA             3            4            4         4       4      5      1   \n",
       "MFT               1            2            2         3       2      2      4   \n",
       "MSE               4            3            3         5       5      1      5   \n",
       "MUE               5            5            5         1       1      3      3   \n",
       "Vecmap            2            1            1         2       3      4      2   \n",
       "\n",
       "        WT p@1  WT p@10  WT p@5  Our dataset, f1  EN-RU WMT, f1  \n",
       "BiCCA        3        3       3                3              1  \n",
       "MFT          4        5       4                1              2  \n",
       "MSE          2        1       1                4              4  \n",
       "MUE          5        4       5                5              5  \n",
       "Vecmap       1        2       2                2              3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "joint_metrics = pandas.concat([intrinsic_metrics, word_translation_metrics, extrinsic_metrics_flat], axis=1)\n",
    "joint_metrics.rename({'{} {}'.format(old_pref, metric) : '{} {}'.format(new_pref, metric)\n",
    "                      for old_pref, new_pref in [('para strict', 'Our dataset,'),\n",
    "                                                 ('yandex wmt', 'EN-RU WMT,')]\n",
    "                      for metric in ['f1', 'p', 'r'] },\n",
    "                     inplace=True,\n",
    "                     axis=1)\n",
    "joint_metrics.drop([c for c in joint_metrics.columns if c.endswith(' r') or  c.endswith(' p')],\n",
    "                   inplace=True,\n",
    "                   axis=1)\n",
    "display(joint_metrics)\n",
    "joint_metrics_norm = (joint_metrics - joint_metrics.mean(0)) / joint_metrics.std(0)\n",
    "display(joint_metrics_norm)\n",
    "joint_metrics_order = joint_metrics.apply(lambda s: (-s).argsort().argsort() + 1)\n",
    "display(joint_metrics_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T11:41:28.098776Z",
     "start_time": "2018-02-22T11:41:28.092844Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joint_metrics.to_csv('../../plag/join_metrics_{}.csv'.format(datetime.datetime.now().isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T11:41:46.598869Z",
     "start_time": "2018-02-22T11:41:46.478550Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "METHOD_COLORS = pandas.Series({\n",
    "    'BiCCA' : (0.8, 0.1, 0.3),\n",
    "    'MFT' : (0.8, 0.1, 0.3),\n",
    "    'MSE' : (0.8, 0.1, 0.3),\n",
    "    'MUE' : (0.1, 0.8, 0.5),\n",
    "    'Vecmap' : (0.8, 0.1, 0.3)\n",
    "})\n",
    "DATASET_COLORS = pandas.Series({\n",
    "    'SimVerb-3074' : (0.15, 0.4, 0.8),\n",
    "    'MEN-1146' : (0.1, 0.8, 0.5),\n",
    "    'RareWord-968' : (0.9, 0.7, 0.2),\n",
    "    'SimLex-739' : (0.9, 0.7, 0.2),\n",
    "    'MTurk-551' : (0.1, 0.8, 0.5),\n",
    "    'SemEval-243' : (0.9, 0.7, 0.2),\n",
    "    'WordRel-193' : (0.1, 0.8, 0.5),\n",
    "    'WordSim-193' : (0.9, 0.7, 0.2),\n",
    "    'Verb-115' : (0.15, 0.4, 0.8),\n",
    "    'YP-111' : (0.15, 0.4, 0.8),\n",
    "    'RG-54' : (0.9, 0.7, 0.2),\n",
    "    'MC-28' : (0.9, 0.7, 0.2),\n",
    "    'Our dataset, f1' : (0.8, 0.1, 0.3),\n",
    "    'Our p' : (0.8, 0.1, 0.3),\n",
    "    'Our r' : (0.8, 0.1, 0.3),\n",
    "    'EN-RU WMT, f1' : (0.8, 0.1, 0.3),\n",
    "    'Yandex p' : (0.8, 0.1, 0.3),\n",
    "    'Yandex r' : (0.8, 0.1, 0.3),\n",
    "    'WT p@1' : (0.5, 0.1, 0.9),\n",
    "    'WT p@5' : (0.5, 0.1, 0.9),\n",
    "    'WT p@10' : (0.5, 0.1, 0.9),\n",
    "})\n",
    "\n",
    "def make_clustermap(metrics, method='average',\n",
    "#                     metric='correlation',\n",
    "                    metric=lambda a, b: 1 - scipy.stats.spearmanr(a, b)[0],\n",
    "                    figsize=(4.3, 4.3), row_colors=METHOD_COLORS, col_colors=DATASET_COLORS, out_file_prefix=None):\n",
    "#     cm1 = sns.clustermap(metrics, method=method, metric=metric, figsize=figsize,\n",
    "#                          row_colors=row_colors, col_colors=col_colors)\n",
    "    cm2 = sns.clustermap(metrics.corr(), method=method, metric=metric, figsize=figsize,\n",
    "                         row_colors=col_colors, col_colors=col_colors)\n",
    "#     cm3 = sns.clustermap(metrics.transpose().corr(), col_cluster=False, method=method, metric=metric)\n",
    "    if out_file_prefix:\n",
    "#         cm1.savefig(out_file_prefix + 'methods_over_datasets.eps')\n",
    "#         cm1.savefig(out_file_prefix + 'methods_over_datasets.png')\n",
    "        cm2.savefig(out_file_prefix + 'datasets_over_datasets.eps')\n",
    "        cm2.savefig(out_file_prefix + 'datasets_over_datasets.png')\n",
    "#         cm3.savefig(out_file_prefix + 'methods_over_methods.eps')\n",
    "#         cm3.savefig(out_file_prefix + 'methods_over_methods.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T13:46:21.604531Z",
     "start_time": "2018-02-22T13:46:19.916938Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f28fbce7a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_clustermap(joint_metrics, out_file_prefix='../../plag/joint_metrics_real_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T11:04:00.445921Z",
     "start_time": "2018-02-22T11:04:00.443361Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make_clustermap(joint_metrics_order, out_file_prefix='../../plag/joint_metrics_order_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T11:04:03.711670Z",
     "start_time": "2018-02-22T11:04:03.708104Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make_clustermap(joint_metrics_norm, out_file_prefix='../../plag/joint_metrics_order_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "notify_time": "10",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "333px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "848px",
    "left": "0px",
    "right": "1708px",
    "top": "111px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
